{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efficient-performer",
   "metadata": {},
   "source": [
    "# MorphCT\n",
    "\n",
    "goal: \n",
    " - atomistic gsd snapshot -> \n",
    " - assign chromophores -> \n",
    " - do QCC calcs -> \n",
    " - run KMC -> \n",
    " - calculate mobility\n",
    "\n",
    "current schema:\n",
    " - xml file\n",
    " - chromphore params set in par.py\n",
    " - if starting with atomistic, we can skip fine graining and molecular dynamics and only run:\n",
    "     - execute_obtain_chromophores = False                                             \n",
    "     - execute_ZINDO = False                                                           \n",
    "     - execute_calculate_transfer_integrals = False                                    \n",
    "     - execute_calculate_mobility = False    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "collect-superior",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jenny/miniconda3/envs/morphct-dev/lib/python3.8/site-packages/scipy/special/orthogonal.py:81: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  from numpy import (exp, inf, pi, sqrt, floor, sin, cos, around, int,\n",
      "/Users/jenny/miniconda3/envs/morphct-dev/lib/python3.8/site-packages/scipy/special/orthogonal.py:81: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  from numpy import (exp, inf, pi, sqrt, floor, sin, cos, around, int,\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import multiprocessing as mp\n",
    "\n",
    "import ele\n",
    "import freud\n",
    "import gsd.hoomd\n",
    "import mbuild as mb\n",
    "import numpy as np\n",
    "from openbabel import openbabel\n",
    "from openbabel import pybel\n",
    "import pyscf\n",
    "from pyscf.semiempirical import MINDO3\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "from morphct.code import obtain_chromophores as oc\n",
    "from morphct import transfer_integrals as ti\n",
    "from morphct import execute_qcc as eqcc\n",
    "from morphct import mobility_kmc as kmc\n",
    "from morphct import chromophores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "wired-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_qcc_input(qcc_input):\n",
    "    comp = mb.Compound()\n",
    "    for line in qcc_input.split(\";\")[:-1]:\n",
    "        atom, x, y, z = line.split()\n",
    "        xyz = np.array([x,y,z], dtype=float)\n",
    "        # Angstrom -> nm\n",
    "        xyz /= 10\n",
    "        comp.add(mb.Particle(name=atom,pos=xyz))\n",
    "    comp.visualize().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-logistics",
   "metadata": {},
   "source": [
    "OK, so I'm looking around for an xml file in the \"obtain chromophores\" tests but all I can find are these pickle files. I want to view them before I continue. ovito and vmd no longer support xmls... gah --> using mbuild."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "extended-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"tests/assets/donor_polymer/OC/donor_polymer_post_obtain_chromophores.pickle\"\n",
    "(\n",
    "    AA_morphdict, \n",
    "    CG_morphdict, \n",
    "    CGtoAAID_list, \n",
    "    param_dict, \n",
    "    chromo_list_old\n",
    ") = pickle.load(open(path,\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hybrid-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_types = list(set(AA_morphdict['type']))\n",
    "bond_list = []\n",
    "for name,i,j in AA_morphdict[\"bond\"]:\n",
    "    if i < j:\n",
    "        pair = (i,j)\n",
    "    else:\n",
    "        pair = (j,i)\n",
    "    if pair not in bond_list:\n",
    "        bond_list.append(pair)\n",
    "            \n",
    "bond_list_sorted = sorted(bond_list, key=lambda pair: pair[0])\n",
    "bond_array = np.array(bond_list_sorted)\n",
    "\n",
    "snap = gsd.hoomd.Snapshot()\n",
    "snap.configuration.box = np.array([\n",
    "    AA_morphdict[\"lx\"],\n",
    "    AA_morphdict[\"ly\"],\n",
    "    AA_morphdict[\"lz\"],\n",
    "    AA_morphdict[\"xy\"],\n",
    "    AA_morphdict[\"xz\"],\n",
    "    AA_morphdict[\"yz\"]\n",
    "])\n",
    "snap.configuration.dimensions = AA_morphdict[\"dimensions\"]\n",
    "snap.particles.N = AA_morphdict[\"natoms\"]\n",
    "snap.particles.body = AA_morphdict[\"body\"]\n",
    "snap.particles.position = AA_morphdict[\"position\"]\n",
    "snap.particles.charge = AA_morphdict[\"charge\"]\n",
    "snap.particles.diameter = AA_morphdict[\"diameter\"]\n",
    "snap.particles.mass = AA_morphdict[\"mass\"]\n",
    "snap.particles.image = AA_morphdict[\"image\"]\n",
    "snap.particles.types = all_types\n",
    "snap.particles.typeid = [all_types.index(i) for i in AA_morphdict[\"type\"]]\n",
    "snap.bonds.N = len(bond_array)\n",
    "snap.bonds.group = bond_array\n",
    "snap.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "colored-swiss",
   "metadata": {},
   "outputs": [],
   "source": [
    "box = snap.configuration.box[:3]\n",
    "unwrapped_positions = snap.particles.position + snap.particles.image * box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "anticipated-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Run this if you want to confirm that the unwrapped positions are correct in OVITO\n",
    "#with gsd.hoomd.open(name='test.gsd', mode='wb') as f:\n",
    "#    f.append(snap)\n",
    "#    snap.particles.position = unwrapped_positions\n",
    "#    f.append(snap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "prompt-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_dict = {\n",
    "    \"S1\": ele.element_from_symbol(\"S\"), \n",
    "    \"H1\": ele.element_from_symbol(\"H\"), \n",
    "    \"C5\": ele.element_from_symbol(\"C\"), \n",
    "    \"C1\": ele.element_from_symbol(\"C\"), \n",
    "    \"C4\": ele.element_from_symbol(\"C\"), \n",
    "    \"C6\": ele.element_from_symbol(\"C\"), \n",
    "    \"C8\": ele.element_from_symbol(\"C\"), \n",
    "    \"C9\": ele.element_from_symbol(\"C\"), \n",
    "    \"C3\": ele.element_from_symbol(\"C\"), \n",
    "    \"C7\": ele.element_from_symbol(\"C\"), \n",
    "    \"C2\": ele.element_from_symbol(\"C\"),\n",
    "    \"C10\": ele.element_from_symbol(\"C\"),\n",
    "}\n",
    "\n",
    "amber_dict = {\n",
    "    \"c\":  ele.element_from_symbol(\"C\"),\n",
    "    \"c1\": ele.element_from_symbol(\"C\"),\n",
    "    \"c2\": ele.element_from_symbol(\"C\"),\n",
    "    \"c3\": ele.element_from_symbol(\"C\"),\n",
    "    \"ca\": ele.element_from_symbol(\"C\"),\n",
    "    \"cp\": ele.element_from_symbol(\"C\"),\n",
    "    \"cq\": ele.element_from_symbol(\"C\"),\n",
    "    \"cc\": ele.element_from_symbol(\"C\"),\n",
    "    \"cd\": ele.element_from_symbol(\"C\"),\n",
    "    \"ce\": ele.element_from_symbol(\"C\"),\n",
    "    \"cf\": ele.element_from_symbol(\"C\"),\n",
    "    \"cg\": ele.element_from_symbol(\"C\"),\n",
    "    \"ch\": ele.element_from_symbol(\"C\"),\n",
    "    \"cx\": ele.element_from_symbol(\"C\"),\n",
    "    \"cy\": ele.element_from_symbol(\"C\"),\n",
    "    \"cu\": ele.element_from_symbol(\"C\"),\n",
    "    \"cv\": ele.element_from_symbol(\"C\"),\n",
    "    \"h1\": ele.element_from_symbol(\"H\"),\n",
    "    \"h2\": ele.element_from_symbol(\"H\"),\n",
    "    \"h3\": ele.element_from_symbol(\"H\"),\n",
    "    \"h4\": ele.element_from_symbol(\"H\"),\n",
    "    \"h5\": ele.element_from_symbol(\"H\"),\n",
    "    \"ha\": ele.element_from_symbol(\"H\"),\n",
    "    \"hc\": ele.element_from_symbol(\"H\"),\n",
    "    \"hn\": ele.element_from_symbol(\"H\"),\n",
    "    \"ho\": ele.element_from_symbol(\"H\"),\n",
    "    \"hp\": ele.element_from_symbol(\"H\"),\n",
    "    \"hs\": ele.element_from_symbol(\"H\"),\n",
    "    \"hw\": ele.element_from_symbol(\"H\"),\n",
    "    \"hx\": ele.element_from_symbol(\"H\"),\n",
    "    \"f\":  ele.element_from_symbol(\"F\"),\n",
    "    \"cl\": ele.element_from_symbol(\"Cl\"),\n",
    "    \"br\": ele.element_from_symbol(\"Br\"),\n",
    "    \"i\":  ele.element_from_symbol(\"I\"),\n",
    "    \"n\":  ele.element_from_symbol(\"N\"),\n",
    "    \"n1\": ele.element_from_symbol(\"N\"),\n",
    "    \"n2\": ele.element_from_symbol(\"N\"),\n",
    "    \"n3\": ele.element_from_symbol(\"N\"),\n",
    "    \"n4\": ele.element_from_symbol(\"N\"),\n",
    "    \"na\": ele.element_from_symbol(\"N\"),\n",
    "    \"nb\": ele.element_from_symbol(\"N\"),\n",
    "    \"nc\": ele.element_from_symbol(\"N\"),\n",
    "    \"nd\": ele.element_from_symbol(\"N\"),\n",
    "    \"ne\": ele.element_from_symbol(\"N\"),\n",
    "    \"nf\": ele.element_from_symbol(\"N\"),\n",
    "    \"nh\": ele.element_from_symbol(\"N\"),\n",
    "    \"no\": ele.element_from_symbol(\"N\"),\n",
    "    \"o\":  ele.element_from_symbol(\"O\"),\n",
    "    \"oh\": ele.element_from_symbol(\"O\"),\n",
    "    \"os\": ele.element_from_symbol(\"O\"),\n",
    "    \"ow\": ele.element_from_symbol(\"O\"),\n",
    "    \"p2\": ele.element_from_symbol(\"P\"),\n",
    "    \"p3\": ele.element_from_symbol(\"P\"),\n",
    "    \"p4\": ele.element_from_symbol(\"P\"),\n",
    "    \"p5\": ele.element_from_symbol(\"P\"),\n",
    "    \"pb\": ele.element_from_symbol(\"P\"),\n",
    "    \"pc\": ele.element_from_symbol(\"P\"),\n",
    "    \"pd\": ele.element_from_symbol(\"P\"),\n",
    "    \"pe\": ele.element_from_symbol(\"P\"),\n",
    "    \"pf\": ele.element_from_symbol(\"P\"),\n",
    "    \"px\": ele.element_from_symbol(\"P\"),\n",
    "    \"py\": ele.element_from_symbol(\"P\"),\n",
    "    \"s\":  ele.element_from_symbol(\"S\"),\n",
    "    \"s2\": ele.element_from_symbol(\"S\"),\n",
    "    \"s4\": ele.element_from_symbol(\"S\"),\n",
    "    \"s6\": ele.element_from_symbol(\"S\"),\n",
    "    \"sh\": ele.element_from_symbol(\"S\"),\n",
    "    \"ss\": ele.element_from_symbol(\"S\"),\n",
    "    \"sx\": ele.element_from_symbol(\"S\"),\n",
    "    \"sy\": ele.element_from_symbol(\"S\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "danish-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "smarts_str = \"c1cscc1CCCCCC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "suspended-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "aaids = chromophores.get_chromo_ids_smiles(snap, smarts_str, conversion_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "important-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromo_list = []\n",
    "for i,aaid in enumerate(aaids):\n",
    "    chromo_list.append(chromophores.Chromophore(i, snap, aaid, \"donor\", conversion_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-shade",
   "metadata": {},
   "source": [
    "Next let's get the neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "consolidated-attitude",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n"
     ]
    }
   ],
   "source": [
    "qcc_pairs = chromophores.set_neighbors_voronoi(\n",
    "    chromo_list, snap, conversion_dict, d_cut=min(box)/2\n",
    ")\n",
    "print(len(qcc_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "patient-period",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thisval': 9}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {}\n",
    "def myfun(dic,number):\n",
    "    dic[\"thisval\"] = number\n",
    "\n",
    "myfun(mydict,9)\n",
    "mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "careful-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checked and all pairs look reasonable!\n",
    "#i = 13\n",
    "#visualize_qcc_input(qcc_pairs[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-breast",
   "metadata": {},
   "source": [
    "next need to run ZINDO\n",
    "\n",
    "`eqcc.get_homolumo(chromo_list[0].qcc_input)` returns HOMO-1, HOMO, LUMO, LUMO+1\n",
    "\n",
    "`eqcc.singles_homolumo` does for all chromophores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "reliable-swedish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jenny/Projects/morphct/notebook_output/singles_energies.txt\n"
     ]
    }
   ],
   "source": [
    "outpath = os.path.join(os.getcwd(), \"notebook_output\")\n",
    "s_filename = os.path.join(outpath, \"singles_energies.txt\")\n",
    "print(s_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "representative-martial",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#data = eqcc.singles_homolumo(chromo_list, s_filename)\n",
    "#\n",
    "#CPU times: user 26.1 ms, sys: 42.2 ms, total: 68.3 ms\n",
    "#Wall time: 3.36 s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-sierra",
   "metadata": {},
   "source": [
    "This gets the energy values of the chromophores using the single inputs and writes them to a file. No energy values are set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "pursuant-switch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "10 10\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "chromo = chromo_list[0]\n",
    "print(chromo.homo)\n",
    "print(len(chromo.neighbors), len(chromo.neighbors_delta_e))\n",
    "print(chromo.neighbors_delta_e[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-turner",
   "metadata": {},
   "source": [
    "Next compute the pair energies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ordinary-billion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jenny/Projects/morphct/notebook_output/dimer_energies.txt\n"
     ]
    }
   ],
   "source": [
    "d_filename = os.path.join(outpath, \"dimer_energies.txt\")\n",
    "print(d_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "worldwide-stadium",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#dimer_data = eqcc.dimer_homolumo(qcc_pairs, d_filename)\n",
    "#\n",
    "#CPU times: user 22.5 ms, sys: 31.9 ms, total: 54.4 ms\n",
    "#Wall time: 31.9 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "lesser-dispute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.01337182 -8.5404688   0.17193304  0.86523495]\n",
      "((0, 1), (-8.709172080560524, -8.217563821747918, -0.2643404153714356, 0.35184321402966473))\n"
     ]
    }
   ],
   "source": [
    "data = eqcc.get_singlesdata(s_filename)\n",
    "print(data[0])\n",
    "dimer_data = eqcc.get_dimerdata(d_filename)\n",
    "print(dimer_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "balanced-angola",
   "metadata": {},
   "outputs": [],
   "source": [
    "eqcc.set_energyvalues(chromo_list, s_filename, d_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "charged-mercy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8.540468797580658\n",
      "10 10\n",
      "-0.016112646652969076\n"
     ]
    }
   ],
   "source": [
    "print(chromo.homo)\n",
    "print(len(chromo.neighbors), len(chromo.neighbors_delta_e))\n",
    "print(chromo.neighbors_delta_e[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-header",
   "metadata": {},
   "source": [
    "OK, I think I should be ready to run KMC. Before it'll work we need to add some things to the param dict and change some paths.\n",
    "\n",
    "```\n",
    "notebook_outputs/KMC/ \n",
    "```\n",
    "\n",
    "run_kmc : single_core_run_mob_KMC\n",
    "\n",
    "kmc : mobility_KMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sustainable-communication",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = param_dict['random_seed_override']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "uniform-morocco",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_list = kmc.get_jobslist([1.00e-13, 1.00e-12], n_holes=10, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "above-parking",
   "metadata": {},
   "outputs": [],
   "source": [
    "KMC_directory = os.path.join(outpath, \"KMC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-julian",
   "metadata": {},
   "source": [
    "Multiprocessing gives a reasonable speedup! (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "proper-swiss",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#\n",
    "#box = snap.configuration.box[:3]\n",
    "#temp = 300\n",
    "#\n",
    "#running_jobs = []\n",
    "#pipes = []\n",
    "#\n",
    "#for jobs in jobs_list:\n",
    "#    child_seed = np.random.randint(0, 2 ** 32)                              \n",
    "#                                                                            \n",
    "#    recv_end, send_end = mp.Pipe(False)                                     \n",
    "#    p = mp.Process(                                                         \n",
    "#            target=kmc.run_single_kmc,                                          \n",
    "#            args=(                                                          \n",
    "#                jobs,                                                       \n",
    "#                KMC_directory,                                              \n",
    "#                chromo_list,                                                \n",
    "#                box,                                                        \n",
    "#                temp,                                                     \n",
    "#                ),                                                          \n",
    "#            kwargs={                                                                                                                       \n",
    "#                \"seed\": child_seed,                                         \n",
    "#                \"send_end\": send_end,                                                                             \n",
    "#                }                                                           \n",
    "#            )                                                               \n",
    "#    running_jobs.append(p) \n",
    "#    pipes.append(recv_end)                                                  \n",
    "#    p.start()\n",
    "#    \n",
    "#for p in running_jobs:                                                      \n",
    "#    p.join()                                                                \n",
    "#\n",
    "#carrier_data_list = [x.recv() for x in pipes]  \n",
    "#\n",
    "#CPU times: user 13.3 ms, sys: 20.9 ms, total: 34.1 ms\n",
    "#Wall time: 1.67 s\n",
    "\n",
    "#%%time\n",
    "#\n",
    "#box = snap.configuration.box[:3]\n",
    "#temp = 300\n",
    "#\n",
    "#carrier_data_list = []\n",
    "#\n",
    "#for jobs in jobs_list: \n",
    "#    child_seed = np.random.randint(0, 2 ** 32) \n",
    "#    data = kmc.run_single_kmc(\n",
    "#        jobs,                                                       \n",
    "#        KMC_directory,                                              \n",
    "#        chromo_list,                                                \n",
    "#        box,                                                        \n",
    "#        temp,                                                                                                                                                                        \n",
    "#        seed= child_seed\n",
    "#    )                                                             \n",
    "#\n",
    "#    carrier_data_list.append(data)\n",
    "\n",
    "#CPU times: user 3.67 s, sys: 535 ms, total: 4.21 s\n",
    "#Wall time: 4.02 s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-vienna",
   "metadata": {},
   "source": [
    "# for next time\n",
    "- make vprint loggable based on cpu_rank √\n",
    "- work on combined_data - get centers √\n",
    "- finish kmc_analyze - got to line 2477 - now on line 743\n",
    "    - updating to use freud clustering module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "mediterranean-location",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All KMC jobs completed!\n",
      "Combining outputs...\n"
     ]
    }
   ],
   "source": [
    "combined_data = kmc.run_kmc(\n",
    "    jobs_list, KMC_directory, chromo_list, snap, 300, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "vulnerable-attitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start = 722\n",
    "#end = 782\n",
    "#with open(\"./morphct/utils/kmc_analyze.py\", \"r\") as f:\n",
    "#    lines = f.readlines()\n",
    "#print(*[line for line in lines[start-1:end]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "interpreted-billion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examining the donor material...\n",
      "Calculating clusters...\n",
      "Examining the acceptor material...\n",
      "No material found. Continuing...\n"
     ]
    }
   ],
   "source": [
    "rmax = None\n",
    "box = snap.configuration.box\n",
    "species = [\"donor\", \"acceptor\"]\n",
    "clusters = []\n",
    "for sp_i, sp in enumerate(species):\n",
    "    chromo_ids = [c.id for c in chromo_list if c.species == sp]\n",
    "    positions = np.array([chromo_list[i].center for i in chromo_ids])\n",
    "    print(f\"Examining the {sp} material...\")\n",
    "    if len(positions) == 0:\n",
    "        print(\"No material found. Continuing...\")\n",
    "        clusters.append(None)   \n",
    "        continue\n",
    "    print(\"Calculating clusters...\")\n",
    "    if rmax is None:\n",
    "        rmax = max(box)/4\n",
    "\n",
    "    cl = freud.cluster.Cluster()\n",
    "\n",
    "    cl.compute((box,positions), neighbors={'r_max': rmax})\n",
    "    clusters.append(cl)\n",
    "    #for chromo_ID, cluster_ID in enumerate(clusters_list):\n",
    "    #    cluster_dict[chromo_ID] = cluster_ID\n",
    "    #cluster_freq = {}\n",
    "    #for cluster_ID in set(clusters_list):\n",
    "    #    cluster_freq[cluster_ID] = clusters_list.count(cluster_ID)\n",
    "    #species_psi[type_i] = sum(\n",
    "    #        [p for p in cluster_freq.values() if p > 6]\n",
    "    #) / len(clusters_list)\n",
    "    #clusters_total[type_i] = len(cluster_freq.keys())\n",
    "    #clusters_large[type_i] = len(\n",
    "    #    [k for k, v in cluster_freq.items() if v > 6]\n",
    "    #)\n",
    "    #clusters_biggest[type_i] = np.max(list(cluster_freq.values()))\n",
    "    #clusters_cutoffs[type_i] = [\n",
    "    #    cutoff_dict[cut_type][type_i]\n",
    "    #    for cut_type in [\"separation\", \"orientation\", \"ti\", \"freq\"]\n",
    "    #]\n",
    "    #print(\"----------------------------------------\")\n",
    "    #print(f\"{species_type}: Detected {clusters_total[type_i]} total\")\n",
    "    #print(f\"and large {clusters_large[type_i]} clusters (size > 6).\")\n",
    "    #print(f\"Largest cluster size ={clusters_biggest[type_i]} chromophores.\")\n",
    "    #print(\n",
    "    #    f'Ratio in \"large\" clusters: {species_psi[type_i]:.3f}'\n",
    "    #    )\n",
    "    #print(\"----------------------------------------\")\n",
    "    #cluster_dicts[type_i] = cluster_dict\n",
    "    #cluster_freqs[type_i] = cluster_freq\n",
    "#return (\n",
    "#    cluster_dicts,\n",
    "#    cluster_freqs,\n",
    "#    clusters_total,\n",
    "#    clusters_large,\n",
    "#    clusters_biggest,\n",
    "#    clusters_cutoffs,\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "perceived-diploma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]]\n",
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]]\n",
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(clusters[0].num_clusters)\n",
    "print(clusters[0].cluster_idx)\n",
    "print(clusters[0].cluster_keys)\n",
    "sortedcl = sorted(clusters[0].cluster_keys, key=lambda i: len(i), reverse=True)\n",
    "print(clusters[0].cluster_keys)\n",
    "print(sortedcl)\n",
    "print(clusters[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "brazilian-probability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intra_crd\n",
      "intra_mrd\n",
      "inter_crd\n",
      "inter_mrd\n",
      "intra_cra\n",
      "intra_mra\n",
      "inter_cra\n",
      "inter_mra\n",
      "intra_crd\n",
      "intra_cra\n",
      "intra_mrd\n",
      "intra_mra\n",
      "inter_crd\n",
      "inter_cra\n",
      "inter_mrd\n",
      "inter_mra\n"
     ]
    }
   ],
   "source": [
    "hop_types = [\"intra\", \"inter\"]                                            \n",
    "hop_targets = [\"c\", \"m\"]                                                    \n",
    "# hop_properties = [\"r\", \"T\"]                                               \n",
    "species = [\"d\", \"a\"]      \n",
    "\n",
    "# Update the dataDict                                                       \n",
    "for sp in species:                                                   \n",
    "    for hop_type in hop_types:                                              \n",
    "        for target in hop_targets:  \n",
    "            hop_name = f\"{hop_type}_{target}r{sp}\"  \n",
    "            print(hop_name)\n",
    "for hop_type,target,sp in itertools.product(hop_types,hop_targets,species):\n",
    "    hop_name = f\"{hop_type}_{target}r{sp}\"  \n",
    "    print(hop_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "minor-catering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 100.0]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl = clusters[0]\n",
    "sizes = [np.log10(len(c)) for c in cl.cluster_keys if len(c) > 5]\n",
    "[1, 10**np.ceil(max(sizes))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-force",
   "metadata": {},
   "source": [
    "# OUTDATED PAST HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "from morphct.utils import kmc_analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmc_analyze.main(\n",
    "    AA_morphdict, \n",
    "    CG_morphdict, \n",
    "    CGtoAAID_list, \n",
    "    param_dict,                                                             \n",
    "    chromo_list,                                                            \n",
    "    [combined_data],                                                      \n",
    "    KMC_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-willow",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
